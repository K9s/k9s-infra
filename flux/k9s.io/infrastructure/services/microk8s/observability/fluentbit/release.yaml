apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: fluent-bit
  annotations:
    kustomize.toolkit.fluxcd.io/substitute: disabled
spec:
  interval: 10m
  chart:
    spec:
      version: 0.39.0
      chart: fluent-bit
      sourceRef:
        kind: HelmRepository
        name: fluent
      interval: 1m
  install:
    crds: CreateReplace
  upgrade:
    crds: CreateReplace
  values:
    logLevel: info

    dashboards:
      enabled: true

    serviceMonitor:
      enabled: true

    service:
      annotations:
       prometheus.io/path: "/api/v1/metrics/prometheus"
       prometheus.io/port: "2020"
       prometheus.io/scrape: "true"

    config:
      service: |
        [SERVICE]
            Flush                   {{ .Values.flush }}
            Log_Level               {{ .Values.logLevel }}
            Daemon                  off
            Parsers_File            custom_parsers.conf
            HTTP_Server             On
            HTTP_Listen             0.0.0.0
            HTTP_Port               {{ .Values.metricsPort }}
            Health_Check            On
            HC_Errors_Count         5
            HC_Retry_Failure_Count  5
            HC_Period               5
            storage.metrics         true
            storage.path            /var/log/flb_buffer
            storage.pause_on_chunks_overlimit On
            scheduler.cap           600

      ## https://docs.fluentbit.io/manual/pipeline/inputs
      inputs: |
        [INPUT]
            Name                  tail
            Alias                 in.kube.cluster
            Tag                   in.kube.cluster.*
            Path                  /var/log/containers/*.log
            Parser                cri
            multiline.parser      docker, cri
            DB                    /var/log/flb_kube.db
            storage.type          memrb
            Mem_Buf_Limit         50MB
            Buffer_Chunk_Size     256k
            Buffer_Max_Size       1M
            Skip_Long_Lines       On
            Skip_Empty_Lines      On
            Refresh_Interval      10
            #threaded              on
        
        [INPUT]
            Name                  tail
            Alias                 in.host.auth
            Tag                   in.host.auth.*
            Path                  /var/log/auth.log
            DB                    /var/log/flb_auth_log.db
            storage.type          memrb
            Mem_Buf_Limit         50MB
            Buffer_Chunk_Size     256k
            Buffer_Max_Size       1M
            Skip_Empty_Lines      On
            Refresh_Interval      10
            #threaded              on

        [INPUT]
            Name                  systemd
            Alias                 in.host.systemd
            Tag                   in.host.systemd.*
            Systemd_Filter        _SYSTEMD_UNIT=snap.microk8s.daemon-apiserver-kicker.service 
            Systemd_Filter        _SYSTEMD_UNIT=snap.microk8s.daemon-cluster-agent.service
            Systemd_Filter        _SYSTEMD_UNIT=snap.microk8s.daemon-containerd.service
            Systemd_Filter        _SYSTEMD_UNIT=snap.microk8s.daemon-k8s-dqlite.service
            Systemd_Filter        _SYSTEMD_UNIT=snap.microk8s.daemon-kubelite.service
            Systemd_Filter        _SYSTEMD_UNIT=ssh.service
            Systemd_Filter        _SYSTEMD_UNIT=fstrim.service
            Systemd_Filter        _SYSTEMD_UNIT=iscsid.service
            DB                    /var/log/flb_systemd.db
            storage.type          memrb
            Mem_Buf_Limit         50MB
            Strip_Underscores     On

      ## https://docs.fluentbit.io/manual/pipeline/filters
      filters: |
        [FILTER]
            Name                  lua
            Alias                 flb_tags
            Match                 *
            script                /fluent-bit/scripts/sanitize_records.lua
            call                  flb_tags
            type_array_key        tags
        
        # Kubernetes
        [FILTER]
            Name                  kubernetes
            Alias                 kubernetes
            Match                 in.kube.cluster.*
            Kube_URL              https://kubernetes.default.svc:443
            Kube_CA_File          /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
            Kube_Token_File       /var/run/secrets/kubernetes.io/serviceaccount/token
            Kube_Tag_Prefix       in.kube.cluster.var.log.containers.
            Merge_Log             Off
            Buffer_Size           0
            K8S-Logging.Parser    On
            K8S-Logging.Exclude   On
            Annotations           On
            Labels                Off
        
        [FILTER]
            Name                  nest
            Alias                 lift.kubernetes
            Match                 in.kube.cluster.*
            Operation             lift
            Nested_under          kubernetes
            Add_prefix            kubernetes_
    
        [FILTER]
            Name                  nest
            Alias                 lift.kubernetes.labels
            Match                 in.kube.cluster.*
            Operation             lift
            Nested_under          kubernetes_labels
            Add_prefix            kubernetes_labels/
    
        [FILTER]
            Name                  nest
            Alias                 lift.kubernetes.annotations
            Match                 in.kube.cluster.*
            Operation             lift
            Nested_under          kubernetes_annotations
            Add_prefix            kubernetes_annotations/
    
        # Raw Logs
        [FILTER]
            Name                  rewrite_tag
            Alias                 raw.ingest
            Emitter_Name          raw.ingest
            Match                 in.*
            Rule                  $_flb_processed ^. raw.ingest.$TAG[1].$TAG[2] true
            
        # Structured Logs
        [FILTER]
            Name                  rewrite_tag
            Alias                 structured.ingest
            Emitter_Name          structured.ingest
            Match                 in.*
            Rule                  $_flb_processed ^. structured.ingest.$TAG[1].$TAG[2] false
            
        [FILTER]
            Name                  modify
            Alias                 structured.rename.log
            Match                 structured.*
            Rename                message   log
            Rename                MESSAGE   log
            Rename                msg       log

        [FILTER]
            Name                  modify
            Alias                 structured.modify._reprocessed
            Match                 structured.ingest.*
            Set                   _reprocessed raw
        
        [FILTER]
            Name                  modify
            Alias                 structured.copy._raw_log
            Match                 structured.ingest.*
            Copy                  log _raw_log
    
        ### Multiline Processing START

        [FILTER]
            name                  multiline
            Alias                 structured.multiline
            Emitter_Name          structured.multiline
            match                 structured.ingress.*
            multiline.key_content log
            multiline.parser      cri, docker, go, python, java
            buffer                On

        [FILTER]
            Name                  modify
            Alias                 structured.modify.multiline
            Match                 structured.multiline
            Set                   _reprocessed multiline
            Set                   _reprocessed_multiline true

        ### Multiline Reprocessing END
        
        [FILTER]
            Name                  parser
            Alias                 structured.parse.simple
            Match                 structured.*
            Key_Name              log
            Reserve_Data          On
            Preserve_Key          Off
            Parser                simple-datetime-log-with-level-and-optional-msg
        
        [FILTER]
            Name                  parser
            Alias                 structured.parse.greedy
            Match                 structured.*
            Key_Name              log
            Reserve_Data          On
            Preserve_Key          Off
            Parser                greedy-log-msg
    
        [FILTER]
            Name                  parser
            Alias                 structured.parse
            Match                 structured.*
            Key_Name              log
            Reserve_Data          On
            Preserve_Key          Off
            Parser                json
            Parser                kube-logs
            Parser                containerd
            Parser                apache_nginx_combined
            Parser                apache_error
            Parser                apache
            Parser                k8s-nginx-ingress
            Parser                kibana-logs
            Parser                simple-datetime-msg-1
            Parser                simple-datetime-msg-2
            Parser                simple-datetime-with-level
            Parser                minecraft-java-msg
            Parser                redis
            Parser                simple-level-msg

        # logfmt is too broad to apply for all logs  https://github.com/fluent/fluent-bit/issues/4927 
        [FILTER]
            Name                  parser
            Alias                 structured.parse.logfmt
            Match                 structured.reprocess.logfmt
            Key_Name              log
            Reserve_Data          On
            Preserve_Key          Off
            Parser                logfmt
        
        # If logfmt ^ fails to parse (resulting in log field remaining) rename that field to prevent loop during reprocessing
        [FILTER]
            Name                  modify
            Alias                 structured.reprocess.logfmt.rename.log
            Match                 structured.reprocess.logfmt
            Hard_rename           log         _log
    
        [FILTER]
            Name                  modify
            Alias                 structured.rename.level
            Match                 structured.*
            Rename                severity    level
            Rename                log_level   level
            Rename                log.level   level
            Rename                lvl         level
        
        [FILTER]
            Name                  modify
            Alias                 structured.rename.es
            Match                 structured.*
            Rename                @timestamp  log_timestamp
            Rename                _id         log_id
            Rename                _index      log_index
    
        [FILTER]
            Name                  parser
            Alias                 structured.parse.pass-through
            Match                 structured.*
            Key_Name              msg
            Reserve_Data          On
            Preserve_Key          Off
            Parser                pass-through
    
        [FILTER]
            Name                  lua
            Alias                 structured.normalize
            Match                 structured.*
            script                /fluent-bit/scripts/sanitize_records.lua
            call                  normalize
            type_array_key        tags
        
        # Reprocessing Start
        
        ## Set reprocessing status records
        
        [FILTER]
            Name                  modify
            Alias                 structured.modify.reprocess.logfmt
            Match                 structured.reprocess.logfmt
            Set                   _reprocessed logfmt
            Set                   _reprocessed_logfmt true
        
        [FILTER]
            Name                  modify
            Alias                 structured.modify.reprocess.log
            Match                 structured.reprocess.log
            Set                   _reprocessed log
            Set                   _reprocessed_log true
        
        [FILTER]
            Name                  modify
            Alias                 structured.modify.reprocess.msg
            Match                 structured.reprocess.msg
            Set                   _reprocessed msg
            Set                   _reprocessed_msg true
        
        ## Reprocessing debug
        
        [FILTER]
            Name                  modify
            Alias                 structured.remove._log_.log
            Match                 structured.*
            Remove                _log_remaining
            Condition             Key_does_not_exist    log
        
        [FILTER]
            Name                  modify
            Alias                 structured.copy._log_remaining.log
            Match                 structured.*
            Hard_copy             log _log_remaining
            Condition             Key_exists    log
        
        [FILTER]
            Name                  modify
            Alias                 structured.remove._log_remaining.log
            Match                 structured.*
            Remove                _log_remaining
            Condition             Key_exists    _reprocessed_msg
        
        [FILTER]
            Name                  lua
            Alias                 final.structured.lua.unparsed
            Match                 final.structured
            script                /fluent-bit/scripts/sanitize_records.lua
            call                  unparsed_log
            enable_flb_null       On
        
        ## Reprocessing rewrite tags
        
        [FILTER]
            Name                  rewrite_tag
            Alias                 structured.reprocess.logfmt
            Emitter_Name          structured.reprocess.logfmt
            Match                 structured.*
            Rule                  $log ^\w*=\w*.*=\w* structured.reprocess.logfmt false

        [FILTER]
            Name                  rewrite_tag
            Alias                 structured.reprocess.log
            Emitter_Name          structured.reprocess.log
            Match                 structured.ingest.*
            Rule                  $log ^. structured.reprocess.log false
        
        [FILTER]
            Name                  rewrite_tag
            Alias                 structured.reprocess.msg
            Emitter_Name          structured.reprocess.msg
            Match                 structured.ingest.*
            Rule                  $msg ^. structured.reprocess.msg false
        
        # Reprocessing END

        [FILTER]
            Name                  nest
            Alias                 structured.lift.httprequest
            Match                 structured.*
            Operation             lift
            Nested_under          httprequest
        
        [FILTER]
            Name                  nest
            Alias                 structured.lift.req
            Match                 structured.*
            Operation             lift
            Nested_under          req
        
        [FILTER]
            Name                  nest
            Alias                 structured.lift.res
            Match                 structured.*
            Operation             lift
            Nested_under          res

        [FILTER]
            Name                  lua
            Alias                 structured.normalize.final
            Match                 structured.*
            script                /fluent-bit/scripts/sanitize_records.lua
            call                  normalize
            type_array_key        tags

        [FILTER]
            Name                  modify
            Alias                 structured.rename.message
            Match                 structured.*
            Rename                msg         message
            Rename                log         message
        
        [FILTER]
            Name                  modify
            Alias                 structured.rename.misc
            Match                 structured.*
            Rename                uri           url
            Rename                t             timestamp
            Rename                ts            timestamp
            Rename                time          timestamp
            Rename                log_timestamp timestamp
            Rename                status        statuscode
            Rename                code          statuscode
            Rename                requestmethod method
            Rename                agent         user-agent
            Rename                user_agent    user-agent
            Rename                errors        error
            Rename                err           error
            Rename                host          hostname
            Rename                uname         name
            
        [FILTER]
            Name                  rewrite_tag
            Alias                 final-structured
            Emitter_Name          final-structured
            Emitter_Storage.type  filesystem
            Match                 structured.*
            Rule                  $_flb_processed ^. final.structured false
        
        [FILTER]
            Name                  rewrite_tag
            Alias                 final-raw
            Emitter_Name          final-raw
            Emitter_Storage.type  filesystem
            Match                 raw.*
            Rule                  $_flb_processed ^. final.raw false
        
        [FILTER]
            Name                  modify
            Alias                 remove.flb_processed
            Match                 *
            Remove                _flb_processed
        
        #[FILTER]
        #    Name    grep
        #    Match   *
        ##    Exclude level info
        #    Exclude level debug

      ## https://docs.fluentbit.io/manual/pipeline/outputs
      outputs: |
        [OUTPUT]
            Name                      es
            Alias                     out.es.structured
            Host                      logs-es-http
            Match                     final.structured
            Index                     logs-structured
            Write_Operation           upsert
            Generate_ID               On
            Suppress_Type_Name        On
            Port                      9200
            Time_Key_Nanos            On
            Retry_Limit               10
            tls                       On
            tls.verify                Off
            Trace_Error               On
            Buffer_Size               1M
            storage.total_limit_size  200M
    
        [OUTPUT]
            Name                      es
            Alias                     out.es.raw
            Host                      logs-es-http
            Match                     final.raw
            Index                     logs-raw
            Write_Operation           upsert
            Generate_ID               On
            Suppress_Type_Name        On
            Port                      9200
            Time_Key_Nanos            On
            Retry_Limit               10
            tls                       On
            tls.verify                Off
            Trace_Error               On
            Buffer_Size               1M
            storage.total_limit_size  200M

      ## https://docs.fluentbit.io/manual/pipeline/parsers
      customParsers: |
        [PARSER]
            Name        simple-datetime-log-with-level-and-optional-msg
            Format      regex
            Regex       ^(?<time>\d*-\d*-\d*.\d*:\d*:\d*\.\d*.) (?<log>.*) (?<level>FATAL|ERROR|WARN|INFO|DEBUG|TRACE|UNKNOWN)(: )?(?<msg>.*)?
            Time_Key    time
            Time_Format %Y-%m-%dT%H:%M:%S.%L%z
        
        [PARSER]
            Name        greedy-log-msg
            Format      regex
            Regex       ^(?<log>{.*})(?<msg>.*)
        
        [PARSER]
            Name        cri
            Format      regex
            Regex       ^(?<time>[^ ]+) (?<stream>stdout|stderr) (?<logtag>[^ ]*) (?<log>.*)$
            Time_Key    time
            Time_Format %Y-%m-%dT%H:%M:%S.%L%z
            
        [PARSER]
            Name        apache
            Format      regex
            Regex       ^(?<host>[^ ]*) (?<ident>[^ ]*) (?<user>[^ ]*) \[(?<time>[^\]]*)\] "(?<method>\S+)(?: +(?<path>[^\"]*?)(?: +\S*)?)?" (?<code>[^ ]*) (?<size>[^ ]*)(?: "(?<referer>[^\"]*)" "(?<agent>[^\"]*)")?$
            Time_Key    time
            Time_Format %d/%b/%Y:%H:%M:%S %z
        
        # Combined log format, should work for nginx and apache default configurations
        # TODO compression_ratio is not quite working right and/or not all logs put compression_ratio data into this field (ie sometimes this ends up with ip-addresses)
        [PARSER]
            Name        apache_nginx_combined
            Format      regex
            Regex       ^(?<host>[^ ]*) (?<ident>[^ ]*) (?<user>[^ ]*) \[(?<time>[^\]]*)\] "(?<method>\S+)(?: +(?<path>[^ ]*) +\S*)?" (?<code>[^ ]*)\s*(?<size>[^ ]*)(?: "(?<referer>[^\"]*)" "(?<agent>[^\"]*)(" ")?(?<compression_ratio>[^\"]*)")
            Time_Key    time
            Time_Format %d/%b/%Y:%H:%M:%S %z
        
        # TODO Fix this, it 'works' but is bad
        [PARSER]
            Name        apache_error
            Format      regex
            Regex       ^\[[^ ]* (?<time>[^\]]*)\] \[(?<level>[^\]]*)\](?: \[pid (?<pid>[^\]]*)\])?( \[client (?<client>[^\]]*)\])? (?<msg>.*)$
    
        [PARSER]
            # https://rubular.com/r/IhIbCAIs7ImOkc
            Name        k8s-nginx-ingress
            Format      regex
            Regex       ^(?<host>[^ ]*) - (?<user>[^ ]*) \[(?<time>[^\]]*)\] "(?<method>\S+)(?: +(?<path>[^\"]*?)(?: +\S*)?)?" (?<code>[^ ]*)\s*(?<size>[^ ]*) "(?<referer>[^\"]*)" "(?<agent>[^\"]*)" (?<request_length>[^ ]*) (?<request_time>[^ ]*) \[(?<proxy_upstream_name>[^ ]*)\] (\[(?<proxy_alternative_upstream_name>[^ ]*)\] )?(?<upstream_addr>[^ ]*) (?<upstream_response_length>[^ ]*) (?<upstream_response_time>[^ ]*) (?<upstream_status>[^ ]*) (?<reg_id>[^ ]*).*$
            Time_Key    time
            Time_Format %d/%b/%Y:%H:%M:%S %z
        
        [PARSER]
            Name        json
            Format      json
    
        [PARSER]
            Name        logfmt
            Format      logfmt
        
        [PARSER]
            Name        kibana-logs
            Format      regex
            Regex       ^(?<method>POST|GET|PUT|DELETE) (?<endpoint>[^ ]*) (?<code>[^ ]*) (?<latency_ms>[^ ]*)ms| \- (?<size>\d*.\d*|\d*)(?<size_unit>[^ ]*)$
    
        [PARSER]
            # https://rubular.com/r/KKkEvIYKEvj13a
            Name        kube-logs
            Format      regex
            Regex       ^(?<severity>W|I|E|F)+(?<code>\d{4})+\s(?<time>\d*:\d*:\d*\.\d*)\s*(?<pid>[^\]]*)\s(?<file>\w*\.\w*):(?<line>\d*)\](?<msg>.*)$
            Time_Key    time
            Time_Format %H:%M:%S.%L
    
        [PARSER]
            Name        containerd
            Format      regex
            Regex       ^(?<time>[^\]]*) \[(?<level>[A-Z]*)\]\[([^ ]*)\] (?<file>[^ ]*) (?<line>[\d ]*): (?<msg>.*)
            Time_Key    time
            Time_Format %Y-%m-%d %H:%M:%S.%L
    
        [PARSER]
            Name        simple-level-msg
            Format      regex
            Regex       ^#(?<level>.*):(?<msg>.*)$
    
        [PARSER]
            Name        simple-datetime-with-level
            Format      regex
            Regex       ^\[(?<time>\d*-\d*-\d* \d*:\d*:\d*:\d*) (?<level>[^ ]*)\](?<msg>.*)$
            Time_Key    time
            Time_Format %Y-%m-%d %H:%M:%S:%L
    
        [PARSER]
            Name        simple-datetime-msg-1
            Format      regex
            Regex       ^\[(?<time>\d*-\d*-\d* \d*:\d*:\d*)\](?<msg>.*)$
            Time_Key    time
            Time_Format %Y-%m-%d %H:%M:%S
        
        [PARSER]
            Name        simple-datetime-msg-2
            Format      regex
            Regex       ^[\[]?(?<time>\d*\/\d*\/\d* \d*:\d*:\d*)[\]]?(?<msg>.*)$
            Time_Key    time
            Time_Format %Y/%m/%d %H:%M:%S
    
        [PARSER]
            Name        minecraft-java-msg
            Format      regex
            Regex       ^\[(?<time>\d*:\d*:\d*)\] \[(?<thread>[^\]]*)\/(?<level>[^\]]*)\]: (?<msg>.*)?
            Time_Key    time
            Time_Format %H:%M:%S
    
        [PARSER]
            Name   redis
            Format regex
            Regex  ^(?<pid>\d*):(?<role>[\w])\s(?<time>[^ ]*\s*[^ ]* [^ ]*\s[^ ]*)\s(?<level>[^ ]*)\s(?<msg>.*$)
            Time_Key time
            Time_Format %d %b %Y %H:%M:%S.%L
            Types pid:integer role:string msg:string level:string
    
        [PARSER]
            Name                pass-through
            Format              regex
            Regex               ^(?<msg>.*)$
            Decode_Field_As     escaped     msg

    luaScripts:
      sanitize_records.lua: |
        function all_trim(s)
           local from = s:match"^%s*()"
           return from > #s and "" or s:match(".*%S", from)
        end
        
        function logfmt(t)
            if type(t) == "table" then
                result = ""
                for k,v in pairs(t) do 
                  if type(v) == "table" then
                    value = logfmt(v)
                  else
                    value = v
                  end
        
                  result = result .. k .. "=" .. tostring(value) .. " " 
                end
                return result:gsub("%s$", "")
            else
                return t
            end
        end
        
        function unparsed_log(tag, timestamp, record)
          if record["_log_remaining"] and record["_raw_log"] ~= nil then
            if record["_log_remaining"] == record["_raw_log"] then
              record["_processing_status"] = "failed"
            else
              record["_processing_status"] = "partial"
            end
          else
            record["_processing_status"] = "parsed"
          end
        
          record["_reprocessed"] = record["_processing_status"] .. "(" .. record["_reprocessed"] .. ")"
        
          return 2, timestamp, record
        end
        
        function flb_tags(tag, timestamp, record)
          if not record["_flb_tags"] then 
            record["_flb_tags"] = {}
            record["_flb_processed"] = "yes"
          end
          table.insert(record["_flb_tags"], tag)
          return 2, timestamp, record
        end
        
        local function has_value (tab, val)
            for index, value in ipairs(tab) do
                if value == val then
                    return true
                end
            end
        
            return false
        end
        
        function normalize(tag, timestamp, record)
            _record = {}
        
            for field, value in pairs(record) do
                --Normalize field value and ensure basic types are preserved
                if type(value) == "string" then
                   value = all_trim(value)
        
                   number = tonumber(value)
                   if number then
                       value = number
                   else
                       value = tostring(value)
                   end
        
                   if value == "true" then value = true end
                   if value == "false" then value = false end
                end
                --Ensure field value is lower() then replace spaces and dots with underscores
                field = string.lower(field):gsub("%s", "_"):gsub("%.", "_")
        
                --Normalize level field value to standard log levels
                if field == "level" then
                    value = string.upper(value)
                    
                    -- Redis log levels https://gist.github.com/jgould22/f42ad756fc07143e2a104d7844f39b12
                    if value == "F" then value = "FATAL" end
                    if value == "E" or value == "ERR" or value == "EROR" then value = "ERROR" end
                    if value == "W" or value == "*" or value == "WARNING" then value = "WARN" end
                    if value == "I" or value == "-" then value = "INFO" end
                    if value == "D" or value == "." then value = "DEBUG" end
                    if value == "T" then value = "TRACE" end
                    if value == "#" then value = "NOTICE" end
                    
                    --Add field if loglevel is not one of the expected values create field for troubleshooting
                    if not has_value({'FATAL', 'ERROR', 'WARN', 'INFO', 'DEBUG', 'TRACE', 'UNKNOWN', 'ENGINE', 'CRITICAL', 'NOTICE'}, value) then
                        _record["_invalid_level"] = value
                    end
                end
        
                --Normalize method field value
                if field == "method" then
                    value = string.upper(value)
                end
                
                --Map {} to nil (empty)
                if (type(value) == "table" and next(value) == nil) or value == "{}" then
                    value = nil
                end
                
                --Ensure field name has valid name.  If any field is invalid add to _rejected_fields field for troubleshooting
                if field:match("^[a-zA-Z_][a-zA-Z0-9_%-\\/]*$") then
                    _record[field] = value
                else
                    if not _record["_rejected_fields"] then _record["_rejected_fields"] = "" end
                    _record["_rejected_fields"] = _record["_rejected_fields"] .. field .. "=" .. tostring(logfmt(value)) .. " "
                end
        
                --print("field:", field, "Value:", _record[field], "Value:", type(_record[field]))
            end
        
            if _record["_rejected_fields"] then _record["_rejected_fields"]:gsub("%s$", "") end 
        
            --_record["_ingest_timestamp"] = os.time(os.date("!*t"))
        
            return 2, timestamp, _record
        end
