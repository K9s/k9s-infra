apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: fluent-bit
  annotations:
    kustomize.toolkit.fluxcd.io/substitute: disabled
spec:
  interval: 10m
  chart:
    spec:
      version: 0.36.0
      chart: fluent-bit
      sourceRef:
        kind: HelmRepository
        name: fluent
      interval: 1m
  install:
    crds: CreateReplace
  upgrade:
    crds: CreateReplace
  values:
    logLevel: info

    dashboards:
      enabled: true

    serviceMonitor:
      enabled: true

    service:
      annotations:
       prometheus.io/path: "/api/v1/metrics/prometheus"
       prometheus.io/port: "2020"
       prometheus.io/scrape: "true"

    config:
      service: |
        [SERVICE]
            Flush                   {{ .Values.flush }}
            Log_Level               {{ .Values.logLevel }}
            Daemon                  off
            Parsers_File            custom_parsers.conf
            HTTP_Server             On
            HTTP_Listen             0.0.0.0
            HTTP_Port               {{ .Values.metricsPort }}
            Health_Check            On
            HC_Errors_Count         5
            HC_Retry_Failure_Count  5
            HC_Period               5
            storage.metrics         true
            storage.path            /var/log/flb_buffer
            storage.max_chunks_up   20
            storage.pause_on_chunks_overlimit On
            scheduler.cap           600

      ## https://docs.fluentbit.io/manual/pipeline/inputs
      inputs: |
        [INPUT]
            Name                  tail
            Alias                 input.kube.cluster
            Tag                   input.kube.cluster.*
            Path                  /var/log/containers/*.log
            Parser                cri
            multiline.parser      docker, cri
            DB                    /var/log/flb_kube.db
            storage.type          memrb
            Mem_Buf_Limit         50MB
            Buffer_Chunk_Size     256k
            Buffer_Max_Size       1M
            Skip_Long_Lines       On
            Skip_Empty_Lines      On
            Refresh_Interval      10
            #threaded              on
        
        [INPUT]
            Name                  tail
            Alias                 input.host.auth
            Tag                   input.host.auth.*
            Path                  /var/log/auth.log
            DB                    /var/log/flb_auth_log.db
            storage.type          memrb
            Mem_Buf_Limit         50MB
            Buffer_Chunk_Size     256k
            Buffer_Max_Size       1M
            Skip_Empty_Lines      On
            Refresh_Interval      10
            #threaded              on

        [INPUT]
            Name                  systemd
            Alias                 input.host.systemd
            Tag                   input.host.systemd.*
            Systemd_Filter        _SYSTEMD_UNIT=snap.microk8s.daemon-apiserver-kicker.service 
            Systemd_Filter        _SYSTEMD_UNIT=snap.microk8s.daemon-cluster-agent.service
            Systemd_Filter        _SYSTEMD_UNIT=snap.microk8s.daemon-containerd.service
            Systemd_Filter        _SYSTEMD_UNIT=snap.microk8s.daemon-k8s-dqlite.service
            Systemd_Filter        _SYSTEMD_UNIT=snap.microk8s.daemon-kubelite.service
            Systemd_Filter        _SYSTEMD_UNIT=ssh.service
            Systemd_Filter        _SYSTEMD_UNIT=fstrim.service
            Systemd_Filter        _SYSTEMD_UNIT=iscsid.service
            DB                    /var/log/flb_systemd.db
            storage.type          memrb
            Mem_Buf_Limit         50MB
            Strip_Underscores     On
            #threaded              on

      ## https://docs.fluentbit.io/manual/pipeline/filters
      filters: |
        # Kubernetes
        [FILTER]
            Name                  kubernetes
            Alias                 kubernetes
            Match                 input.kube.cluster.*
            Kube_URL              https://kubernetes.default.svc:443
            Kube_CA_File          /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
            Kube_Token_File       /var/run/secrets/kubernetes.io/serviceaccount/token
            Kube_Tag_Prefix       input.kube.cluster.var.log.containers.
            Merge_Log             Off
            Buffer_Size           0
            K8S-Logging.Parser    On
            K8S-Logging.Exclude   On
            Annotations           On
            Labels                Off
        
        [FILTER]
            Name                  nest
            Alias                 lift.kubernetes
            Match                 input.kube.cluster.*
            Operation             lift
            Nested_under          kubernetes
            Add_prefix            kubernetes_
    
        [FILTER]
            Name                  nest
            Alias                 lift.kubernetes.labels
            Match                 input.kube.cluster.*
            Operation             lift
            Nested_under          kubernetes_labels
            Add_prefix            kubernetes_labels/
    
        [FILTER]
            Name                  nest
            Alias                 lift.kubernetes.annotations
            Match                 input.kube.cluster.*
            Operation             lift
            Nested_under          kubernetes_annotations
            Add_prefix            kubernetes_annotations/
        
        [FILTER]
            Name                  lua
            Alias                 record.log_source
            Match                 input.*
            script                /fluent-bit/scripts/sanitize_records.lua
            call                  log_source
            type_array_key        tags
    
        # Raw Logs
        [FILTER]
            Name                  rewrite_tag
            Alias                 raw-logs.ingest
            Emitter_Name          raw-logs.ingest
            Match                 input.*
            Rule                  $_log_source ^. raw-logs.ingest.$TAG[1].$TAG[2] true
            
        # Structured Logs
        [FILTER]
            Name                  rewrite_tag
            Alias                 structured-logs.ingest
            Emitter_Name          structured-logs.ingest
            Match                 input.*
            Rule                  $_log_source ^. structured-logs.ingest.$TAG[1].$TAG[2] false
            
        [FILTER]
            Name                  modify
            Alias                 structured-logs.rename.log
            Match                 structured-logs.*
            Rename                message   log
            Rename                MESSAGE   log
            Rename                msg       log
        
        [FILTER]
            Name                  modify
            Alias                 structured-logs.rename.log.msg
            Match                 structured-logs.*
            Hard_rename           message   _message
            Hard_rename           MESSAGE   _cap_message
            Hard_rename           msg       _msg

        [FILTER]
            Name                  modify
            Alias                 structured-logs.modify._reprocessed
            Match                 structured-logs.ingest.*
            Set                   _reprocessed no
        
        [FILTER]
            Name                  modify
            Alias                 structured-logs.copy._raw_log
            Match                 structured-logs.ingest.*
            Copy                  log _raw_log
        
        [FILTER]
            Name                  modify
            Alias                 structured-logs.copy._log_last
            Match                 structured-logs.*
            Hard_copy             log _log_last
    
        ### Multiline Processing START
        
        [FILTER]
            name                  multiline
            Alias                 structured-logs.multiline
            Emitter_Name          structured-logs.multiline
            match                 structured-logs.*
            multiline.key_content log
            multiline.parser      cri, docker, go, python, java
            buffer                On
        
        [FILTER]
            Name                  modify
            Alias                 structured-logs.modify.multiline
            Match                 structured-logs.multiline
            Set                   _reprocessed multiline
            Set                   _reprocessed_multiline true
        
        ### Multiline Reprocessing END
        
        [FILTER]
            Name                  parser
            Alias                 structured-logs.parse.simple
            Match                 structured-logs.*
            Key_Name              log
            Reserve_Data          On
            Preserve_Key          Off
            Parser                simple-datetime-log-with-level-and-optional-msg
    
        [FILTER]
            Name                  parser
            Alias                 structured-logs.parse
            Match                 structured-logs.*
            Key_Name              log
            Reserve_Data          On
            Preserve_Key          Off
            Parser                json
            Parser                kube-logs
            Parser                docker-daemon
            Parser                containerd
            Parser                apache_nginx_combined
            Parser                apache_error
            Parser                apache
            Parser                k8s-nginx-ingress
            Parser                kibana-logs
            Parser                simple-datetime-msg-1
            Parser                simple-datetime-msg-2
            Parser                simple-datetime-with-level
            Parser                minecraft-java-msg

        # logfmt is too broad to apply for all logs  https://github.com/fluent/fluent-bit/issues/4927 
        [FILTER]
            Name                  parser
            Alias                 structured-logs.parse.logfmt
            Match                 structured-logs.reprocess.logfmt
            Key_Name              log
            Reserve_Data          On
            Preserve_Key          Off
            Parser                logfmt
        
        # If logfmt ^ fails to parse (resulting in log field remaining) rename that field to prevent loop during reprocessing
        [FILTER]
            Name                  modify
            Alias                 structured-logs.reprocess.logfmt.rename.log
            Match                 structured-logs.reprocess.logfmt
            Hard_rename           log         _log
    
        [FILTER]
            Name                  modify
            Alias                 structured-logs.rename.level
            Match                 structured-logs.*
            Rename                severity    level
            Rename                log_level   level
            Rename                log.level   level
            Rename                lvl         level
        
        [FILTER]
            Name                  modify
            Alias                 structured-logs.rename.es
            Match                 structured-logs.*
            Rename                @timestamp  log_timestamp
            Rename                _id         log_id
            Rename                _index      log_index
    
        [FILTER]
            Name                  parser
            Alias                 structured-logs.parse.pass-through
            Match                 structured-logs.*
            Key_Name              msg
            Reserve_Data          On
            Preserve_Key          Off
            Parser                pass-through
    
        [FILTER]
            Name                  lua
            Alias                 structured-logs.normalize
            Match                 structured-logs.*
            script                /fluent-bit/scripts/sanitize_records.lua
            call                  normalize
            type_array_key        tags
        
        ### Reprocessing START
        
        [FILTER]
            Name                  rewrite_tag
            Alias                 structured-logs.reprocess.logfmt
            Emitter_Name          structured-logs.reprocess.logfmt
            Match                 structured-logs.*
            Rule                  $log ^\S*=.*=.*$ structured-logs.reprocess.logfmt false
        
        [FILTER]
            Name                  modify
            Alias                 structured-logs.modify.reprocess.logfmt
            Match                 structured-logs.reprocess.logfmt
            Set                   _reprocessed logfmt
            Set                   _reprocessed_logfmt true

        [FILTER]
            Name                  rewrite_tag
            Alias                 structured-logs.reprocess.log
            Emitter_Name          structured-logs.reprocess.log
            Match                 structured-logs.ingest.*
            Rule                  $log ^. structured-logs.reprocess.log false
        
        [FILTER]
            Name                  modify
            Alias                 structured-logs.modify.reprocess.log
            Match                 structured-logs.reprocess.log
            Set                   _reprocessed log
            Set                   _reprocessed_log true
        
        [FILTER]
            Name                  rewrite_tag
            Alias                 structured-logs.reprocess.msg
            Emitter_Name          structured-logs.reprocess.msg
            Match                 structured-logs.ingest.*
            Rule                  $msg ^. structured-logs.reprocess.msg false
        
        [FILTER]
            Name                  modify
            Alias                 structured-logs.modify.reprocess.msg
            Match                 structured-logs.reprocess.msg
            Set                   _reprocessed msg
            Set                   _reprocessed_msg true
        
        ### Reprocessing END

        [FILTER]
            Name                  nest
            Alias                 structured-logs.lift.httprequest
            Match                 structured-logs.*
            Operation             lift
            Nested_under          httprequest
        
        [FILTER]
            Name                  nest
            Alias                 structured-logs.lift.req
            Match                 structured-logs.*
            Operation             lift
            Nested_under          req
        
        [FILTER]
            Name                  nest
            Alias                 structured-logs.lift.res
            Match                 structured-logs.*
            Operation             lift
            Nested_under          res

        [FILTER]
            Name                  lua
            Alias                 structured-logs.normalize.final
            Match                 structured-logs.*
            script                /fluent-bit/scripts/sanitize_records.lua
            call                  normalize
            type_array_key        tags

        [FILTER]
            Name                  modify
            Alias                 structured-logs.rename.message
            Match                 structured-logs.*
            Rename                msg         message
            Rename                log         message
            Copy                  _msg        message
            Copy                  _log        message
        
        [FILTER]
            Name                  modify
            Alias                 structured-logs.rename.misc
            Match                 structured-logs.*
            Rename                uri           url
            Rename                t             timestamp
            Rename                ts            timestamp
            Rename                time          timestamp
            Rename                log_timestamp timestamp
            Rename                status        statuscode
            Rename                code          statuscode
            Rename                requestmethod method
            Rename                agent         user-agent
            Rename                user_agent    user-agent
            Rename                errors        error
            Rename                err           error
            Rename                host          hostname
            Rename                uname         name
        
        [FILTER]
            Name                  lua
            Alias                 record.log_tag
            Match                 structured-logs.*
            script                /fluent-bit/scripts/sanitize_records.lua
            call                  log_tag
            type_array_key        tags
        
        [FILTER]
            Name                  rewrite_tag
            Alias                 final-structured-logs
            Emitter_Name          final-structured-logs
            Emitter_Storage.type  filesystem
            Match                 structured-logs.*
            Rule                  $_log_source ^. final.structured-logs false
        
        [FILTER]
            Name                  rewrite_tag
            Alias                 final.raw-logs
            Emitter_Name          final-raw-logs
            Emitter_Storage.type  filesystem
            Match                 raw-logs.*
            Rule                  $_log_source ^. final.raw-logs false
            
        #[FILTER]
        #    Name    grep
        #    Match   *
        ##    Exclude level info
        #    Exclude level debug

      ## https://docs.fluentbit.io/manual/pipeline/outputs
      outputs: |
        [OUTPUT]
            Name                      es
            Alias                     es.structured-logs
            Host                      logs-es-http
            Match                     final.structured-logs
            Index                     logs-structured
            Write_Operation           upsert
            Generate_ID               On
            Suppress_Type_Name        On
            Port                      9200
            Time_Key_Nanos            On
            Retry_Limit               10
            tls                       On
            tls.verify                Off
            Trace_Error               On
            Buffer_Size               1M
            storage.total_limit_size  200M
    
        [OUTPUT]
            Name                      es
            Alias                     es.raw-logs
            Host                      logs-es-http
            Match                     final.raw-logs
            Index                     logs-raw
            Write_Operation           upsert
            Generate_ID               On
            Suppress_Type_Name        On
            Port                      9200
            Time_Key_Nanos            On
            Retry_Limit               10
            tls                       On
            tls.verify                Off
            Trace_Error               On
            Buffer_Size               1M
            storage.total_limit_size  200M

      ## https://docs.fluentbit.io/manual/pipeline/parsers
      customParsers: |
        [PARSER]
            Name        simple-datetime-log-with-level-and-optional-msg
            Format      regex
            Regex       ^(?<time>\d*-\d*-\d*.\d*:\d*:\d*\.\d*.) (?<log>.*) (?<level>FATAL|ERROR|WARN|INFO|DEBUG|TRACE|UNKNOWN)(: )?(?<msg>.*)?
            Time_Key    time
            Time_Format %Y-%m-%dT%H:%M:%S.%L%z
            
        [PARSER]
            Name        docker-daemon
            Format      regex
            Regex       (^\[(?<container>.*)] )?time="(?<time>[^ ]*)" level=(?<level>[^ ]*) (?<log>.*)
            Time_Key    time
            Time_Format %Y-%m-%dT%H:%M:%S

        [PARSER]
            Name        cri
            Format      regex
            Regex       ^(?<time>[^ ]+) (?<stream>stdout|stderr) (?<logtag>[^ ]*) (?<log>.*)$
            Time_Key    time
            Time_Format %Y-%m-%dT%H:%M:%S.%L%z
            
        [PARSER]
            Name        apache
            Format      regex
            Regex       ^(?<host>[^ ]*) (?<ident>[^ ]*) (?<user>[^ ]*) \[(?<time>[^\]]*)\] "(?<method>\S+)(?: +(?<path>[^\"]*?)(?: +\S*)?)?" (?<code>[^ ]*) (?<size>[^ ]*)(?: "(?<referer>[^\"]*)" "(?<agent>[^\"]*)")?$
            Time_Key    time
            Time_Format %d/%b/%Y:%H:%M:%S %z
        
        # Combined log format, should work for nginx and apache default configurations
        # TODO compression_ratio is not quite working right and/or not all logs put compression_ratio data into this field (ie sometimes this ends up with ip-addresses)
        [PARSER]
            Name        apache_nginx_combined
            Format      regex
            Regex       ^(?<host>[^ ]*) (?<ident>[^ ]*) (?<user>[^ ]*) \[(?<time>[^\]]*)\] "(?<method>\S+)(?: +(?<path>[^ ]*) +\S*)?" (?<code>[^ ]*)\s*(?<size>[^ ]*)(?: "(?<referer>[^\"]*)" "(?<agent>[^\"]*)(" ")?(?<compression_ratio>[^\"]*)")
            Time_Key    time
            Time_Format %d/%b/%Y:%H:%M:%S %z
        
        # TODO Fix this, it 'works' but is bad
        [PARSER]
            Name        apache_error
            Format      regex
            Regex       ^\[[^ ]* (?<time>[^\]]*)\] \[(?<level>[^\]]*)\](?: \[pid (?<pid>[^\]]*)\])?( \[client (?<client>[^\]]*)\])? (?<msg>.*)$
    
        [PARSER]
            # https://rubular.com/r/IhIbCAIs7ImOkc
            Name        k8s-nginx-ingress
            Format      regex
            Regex       ^(?<host>[^ ]*) - (?<user>[^ ]*) \[(?<time>[^\]]*)\] "(?<method>\S+)(?: +(?<path>[^\"]*?)(?: +\S*)?)?" (?<code>[^ ]*)\s*(?<size>[^ ]*) "(?<referer>[^\"]*)" "(?<agent>[^\"]*)" (?<request_length>[^ ]*) (?<request_time>[^ ]*) \[(?<proxy_upstream_name>[^ ]*)\] (\[(?<proxy_alternative_upstream_name>[^ ]*)\] )?(?<upstream_addr>[^ ]*) (?<upstream_response_length>[^ ]*) (?<upstream_response_time>[^ ]*) (?<upstream_status>[^ ]*) (?<reg_id>[^ ]*).*$
            Time_Key    time
            Time_Format %d/%b/%Y:%H:%M:%S %z
        
        [PARSER]
            Name        json
            Format      json
    
        [PARSER]
            Name        logfmt
            Format      logfmt
        
        [PARSER]
            Name        kibana-logs
            Format      regex
            Regex       ^(?<method>POST|GET|PUT|DELETE) (?<endpoint>[^ ]*) (?<code>[^ ]*) (?<latency_ms>[^ ]*)ms| \- (?<size>\d*.\d*|\d*)(?<size_unit>[^ ]*)$
    
        [PARSER]
            # https://rubular.com/r/KKkEvIYKEvj13a
            Name        kube-logs
            Format      regex
            Regex       ^(?<severity>W|I|E|F)+(?<code>\d{4})+\s(?<time>\d*:\d*:\d*\.\d*)\s*(?<pid>[^\]]*)\s(?<file>\w*\.\w*):(?<line>\d*)\](?<msg>.*)$
            Time_Key    time
            Time_Format %H:%M:%S.%L
    
        [PARSER]
            Name        containerd
            Format      regex
            Regex       ^(?<time>[^\]]*) \[(?<level>[A-Z]*)\]\[([^ ]*)\] (?<file>[^ ]*) (?<line>[\d ]*): (?<msg>.*)
            Time_Key    time
            Time_Format %Y-%m-%d %H:%M:%S.%L
    
        [PARSER]
            Name        simple-datetime-with-level
            Format      regex
            Regex       ^\[(?<time>\d*-\d*-\d* \d*:\d*:\d*:\d*) (?<level>[^ ]*)\](?<msg>.*)$
            Time_Key    time
            Time_Format %Y-%m-%d %H:%M:%S:%L
    
        [PARSER]
            Name        simple-datetime-msg-1
            Format      regex
            Regex       ^\[(?<time>\d*-\d*-\d* \d*:\d*:\d*)\](?<msg>.*)$
            Time_Key    time
            Time_Format %Y-%m-%d %H:%M:%S
        
        [PARSER]
            Name        simple-datetime-msg-2
            Format      regex
            Regex       ^[\[]?(?<time>\d*\/\d*\/\d* \d*:\d*:\d*)[\]]?(?<msg>.*)$
            Time_Key    time
            Time_Format %Y/%m/%d %H:%M:%S
    
        [PARSER]
            Name        minecraft-java-msg
            Format      regex
            Regex       ^\[(?<time>\d*:\d*:\d*)\] \[(?<thread>[^\]]*)\/(?<level>[^\]]*)\] \[(?<namespace>[^\]]*)]: (?<msg>.*)?
            Time_Key    time
            Time_Format %H:%M:%S
    
        [PARSER]
            Name                pass-through
            Format              regex
            Regex               ^(?<msg>.*)$
            Decode_Field_As     escaped     msg

    luaScripts:
      sanitize_records.lua: |
        function all_trim(s)
           local from = s:match"^%s*()"
           return from > #s and "" or s:match(".*%S", from)
        end
        
        function logfmt(t)
            if type(t) == "table" then
                result = ""
                for k,v in pairs(t) do 
                  if type(v) == "table" then
                    value = logfmt(v)
                  else
                    value = v
                  end
        
                  result = result .. k .. "=" .. tostring(value) .. " " 
                end
                return result:gsub("%s$", "")
            else
                return t
            end
        end
        
        function log_source(tag, timestamp, record)
          record["_log_source"] = tag
          return 2, timestamp, record
        end
        
        function log_tag(tag, timestamp, record)
          record["_log_tag"] = tag
          return 2, timestamp, record
        end
        
        local function has_value (tab, val)
            for index, value in ipairs(tab) do
                if value == val then
                    return true
                end
            end
        
            return false
        end
        
        function normalize(tag, timestamp, record)
            _record = {}
        
            for field, value in pairs(record) do
                --Normalize field value and ensure basic types are preserved
                if type(value) == "string" then
                   value = all_trim(value)
        
                   number = tonumber(value)
                   if number then
                       value = number
                   else
                       value = tostring(value)
                   end
        
                   if value == "true" then value = true end
                   if value == "false" then value = false end
                end
                --Ensure field value is lower() then replace spaces and dots with underscores
                field = string.lower(field):gsub("%s", "_"):gsub("%.", "_")
        
                --Normalize level field value to standard log levels
                if field == "level" then
                    value = string.upper(value)
        
                    if value == "F" then value = "FATAL" end
                    if value == "E" or value == "ERR" or value == "EROR" then value = "ERROR" end
                    if value == "W" or value == "WARNING" then value = "WARN" end
                    if value == "I" then value = "INFO" end
                    if value == "D" then value = "DEBUG" end
                    if value == "T" then value = "TRACE" end
                    
                    --Add field if loglevel is not one of the expected values create field for troubleshooting
                    if not has_value({'FATAL', 'ERROR', 'WARN', 'INFO', 'DEBUG', 'TRACE', 'UNKNOWN', 'ENGINE'}, value) then
                        _record["_invalid_level"] = value
                    end
                end
        
                --Normalize method field value
                if field == "method" then
                    value = string.upper(value)
                end
                
                --Map {} to empty string
                if (type(value) == "table" and next(value) == nil) or value == "{}" then
                    value = nil
                end
                
                --Ensure field name has valid name.  If any field is invalid add to _rejected_fields field for troubleshooting
                if field:match("^[a-zA-Z_][a-zA-Z0-9_%-\\/]*$") then
                    _record[field] = value
                else
                    if not _record["_rejected_fields"] then _record["_rejected_fields"] = "" end
                    _record["_rejected_fields"] = _record["_rejected_fields"] .. field .. "=" .. tostring(logfmt(value)) .. " "
                end
        
                --print("field:", field, "Value:", _record[field], "Value:", type(_record[field]))
            end
        
            if _record["_rejected_fields"] then _record["_rejected_fields"]:gsub("%s$", "") end 
        
            --_record["_ingest_timestamp"] = os.time(os.date("!*t"))
        
            return 2, timestamp, _record
        end
